# √âtape 04 ‚Äì Normalisation et G√©n√©ration des Images RGB pour CNN

## Entr√©es

  - `data/03_windowed/X_windows.npy`
  - `data/03_windowed/y_labels.npy`

> **Note :** Cette √©tape repart des donn√©es brutes de l'√©tape 02. Les images g√©n√©r√©es √† l'√©tape 03 servaient uniquement √† la validation visuelle humaine.

-----

## Ce que fait l‚Äô√©tape 04

  - **Nettoie le signal :** Suppression de la gravit√© (composante DC) et filtrage des fen√™tres "mortes".
  - **Fusionne les axes :** Empile les spectrogrammes des axes vibration (Ax, Ay, Az) en une seule **image RGB** (3 canaux).
  - **Am√©liore la r√©solution temporelle :** Utilise un fort chevauchement (overlap) pour obtenir des images larges malgr√© la courte dur√©e des fen√™tres.
  - **Normalise :** Applique une normalisation robuste (percentiles) pour garantir un bon contraste.
  - **Structure :** Organise les images pour l'entra√Ænement du mod√®le (dossier `05_cnn_input`).

-----

## En d√©tail

Cette √©tape est critique pour transformer des s√©ries temporelles brutes en "tenseurs" d'images optimis√©s pour un R√©seau de Neurones Convolutif (CNN).

Contrairement √† l'√©tape 03 (visualisation), l'objectif ici est de cr√©er des donn√©es dense et normalis√©es pour la machine.

### 1\. Strat√©gie RGB (Ax, Ay, Az)

Au lieu de traiter chaque axe s√©par√©ment, je cr√©e une image composite o√π chaque couleur correspond √† une direction physique :

  - **Canal Rouge (R)** üî¥ : Spectrogramme de l'axe **Ax**
  - **Canal Vert (G)** üü¢ : Spectrogramme de l'axe **Ay**
  - **Canal Bleu (B)** üîµ : Spectrogramme de l'axe **Az**

Cela permet au CNN d'apprendre les corr√©lations spatiales entre les axes (ex: une vibration forte sur X mais faible sur Y cr√©e une couleur sp√©cifique).

### 2\. Corrections Techniques Appliqu√©es

Pour r√©soudre les probl√®mes d'images noires ou trop √©troites rencontr√©s pr√©c√©demment, le pipeline applique les transformations suivantes :

#### A. Suppression de la Gravit√© (`signal.detrend`)

Les acc√©l√©rom√®tres captent la gravit√© (9.81 m/s¬≤), ce qui cr√©e une composante continue √©norme √† 0Hz. Cela "√©crasait" les vibrations utiles lors de la normalisation (rendant l'image noire).

  - **Solution :** Application d'un `detrend` avant la STFT pour centrer le signal sur 0 et ne garder que les vibrations.

#### B. √âtirement Temporel (High Overlap)

Les fen√™tres de 2 secondes (400 points) sont courtes par rapport √† la taille de la FFT (256 points). Sans chevauchement, l'image ne ferait que 2 ou 3 pixels de large.

  - **Solution :** `noverlap = 252` (sur 256). On fait glisser la fen√™tre d'analyse tr√®s doucement pour g√©n√©rer artificiellement une r√©solution temporelle (largeur d'image \~100px).

#### C. Normalisation Robuste

Au lieu d'une normalisation Min-Max classique (sensible aux pics de bruits isol√©s), j'utilise une normalisation par **Percentiles (2% - 99%)**.

  - **R√©sultat :** Le contraste est maximis√© sur la partie utile du signal, rendant les harmoniques de balourd bien visibles.

#### D. Filtrage des Donn√©es Mortes

Certaines fen√™tres issues de la fusion (√©tape 01) contenaient des signaux plats ou nuls.

  - **Action :** Le script rejette automatiquement toute fen√™tre dont l'√©cart-type est `< 0.005`.

-----

## ‚öôÔ∏è Param√®tres de la STFT

```python
FS = 200.0 Hz        # Fr√©quence d'√©chantillonnage
N_FFT = 256          # R√©solution fr√©quentielle (Hauteur image = 129px)
NOVERLAP = 252       # Chevauchement (Largeur image ~ 101px)
WINDOW = 'hann'      # Fen√™trage pour limiter les fuites spectrales
MODE = 'magnitude'   # Amplitude (convertie en dB)
```

-----

## üìä R√©sultats

Les images finales sont des PNG couleur de taille **101 x 129 pixels**.

  - **Sain** : \~551 images (Texture bruit√©e, verticale, peu de lignes horizontales).
  - **Balourd** : \~246 images (Lignes horizontales distinctes correspondant √† la fr√©quence de rotation et ses harmoniques).

-----

## üìÅ Structure de sortie

Les donn√©es sont pr√™tes √† √™tre charg√©es par un `ImageDataGenerator` (Keras) ou `ImageFolder` (PyTorch).

```text
data/05_cnn_input/
‚îú‚îÄ‚îÄ sain/
‚îÇ   ‚îú‚îÄ‚îÄ spec_rgb_0000.png
‚îÇ   ‚îú‚îÄ‚îÄ spec_rgb_0001.png
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ balourd/
    ‚îú‚îÄ‚îÄ spec_rgb_0554.png
    ‚îú‚îÄ‚îÄ spec_rgb_0555.png
    ‚îî‚îÄ‚îÄ ...
```

## le script ```image_quality_check.ipynb```

### 1. V√©rification de la Quantit√© et de l'√âquilibre (`CHECK QUANTITY & BALANCE`)
* **Ce qu'il fait :** Il compte combien d'images vous avez dans le dossier `sain` et dans le dossier `balourd`.
* **Pourquoi c'est important :**
    * **Volume :** Le Deep Learning a besoin de beaucoup de donn√©es. Avec ~800 images au total, vous avez un dataset "petit mais suffisant" pour commencer.
    * **√âquilibre (Balance) :** Si vous avez 1000 images "saines" et seulement 10 images "balourd", le mod√®le va tricher : il va toujours pr√©dire "sain" et aura 99% de r√©ussite, mais il sera inutile.
    * **Votre R√©sultat :** Vous avez un ratio de **1 Balourd pour 2.24 Sain**. C'est un d√©s√©quilibre mod√©r√©. Le script vous avertit que c'est "acceptable", mais cela signifie que lors de l'entra√Ænement (√âtape 05), nous devrons dire au mod√®le : *"Attention, les exemples de Balourd sont rares, donc si tu en vois un, accorde-lui plus d'importance (poids)"*.

### 2. V√©rification des Dimensions et du Format (`CHECK DIMENSIONS & FORMAT`)
* **Ce qu'il fait :** Il ouvre une image au hasard et regarde sa taille (Largeur x Hauteur) et son mode de couleur (RGB).
* **Pourquoi c'est important :**
    * **L'Input du CNN :** Un r√©seau de neurones attend une entr√©e de taille fixe. Si vous lui donnez une image de taille (3, 129) alors qu'il attend du (101, 129), il plantera.
    * **Le bug de l'overlap :** C'est ce test qui nous aurait permis de d√©tecter automatiquement le probl√®me des "bandes verticales" que vous aviez tout √† l'heure. Le script v√©rifie `width > 30` pour s'assurer que l'image contient bien de l'information temporelle.

### 3. V√©rification du Contenu (`CHECK PIXEL VALUES`)
* **Ce qu'il fait :** Il prend 100 images au hasard, les transforme en tableau de nombres, et calcule la moyenne de leur luminosit√©. Si la moyenne est proche de 0 (tout noir), il sonne l'alarme.
* **Pourquoi c'est important :**
    * **D√©tecter les signaux morts :** Comme nous l'avons vu, une fen√™tre temporelle o√π le capteur ne captait rien (ou juste la gravit√© constante) produisait une image noire apr√®s normalisation.
    * **√âviter la pollution :** Si on entra√Æne un mod√®le sur des images noires √©tiquet√©es "balourd", il va apprendre n'importe quoi.
    * **Votre R√©sultat :** "Aucune image noire d√©tect√©e". Cela valide que votre correction avec `signal.detrend` et le filtre `std_val < 0.005` ont bien fonctionn√©.

### 4. Visualisation Comparative (`VISUALISATION COMPARATIVE`)
* **Ce qu'il fait :** Il affiche une grille d'exemples r√©els pour vos yeux.
* **Pourquoi c'est important :**
    * **L'intuition humaine :** L'algorithme ne "voit" pas comme nous. Cette √©tape permet de v√©rifier si *vous* (l'humain) arrivez √† voir une diff√©rence.
    * **Les Motifs :** Dans vos r√©sultats, on voit clairement que les images "Balourd" ont des lignes horizontales bien marqu√©es (les fr√©quences de vibration du d√©faut), alors que les images "Sain" sont plus "bruit√©es" ou verticales. C'est la preuve visuelle que l'information pertinente est bien pr√©sente dans l'image.

En r√©sum√©, ce script vous donne le **feu vert officiel**. Vous savez maintenant que vos donn√©es sont **propres, lisibles, et diff√©renciables**.