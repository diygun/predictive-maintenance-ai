{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd6ca6e",
   "metadata": {},
   "source": [
    "# Entraînement d'un CNN avec des images de spectrogrammes\n",
    "\n",
    "Ce notebook entraîne un réseau de neurones convolutionnel (CNN) en utilisant des images de spectrogrammes des vibrations du moteur. Le jeu de données est divisé en ensembles d'entraînement, de validation et de test. Le modèle entraîné est sauvegardé avec un horodatage et une convention de nommage basée sur les performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f09fe9",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques (libraries) nécessaires\n",
    "\n",
    "Nous allons importer les bibliothèques nécessaires pour le chargement des données, le prétraitement et la construction du modèle CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow keras matplotlib numpy pandas scikit-learn pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec5ca3",
   "metadata": {},
   "source": [
    "## Chargement et prétraitement des données\n",
    "\n",
    "Nous allons charger les images de spectrogrammes depuis le répertoire `data/05_cnn_input`, les prétraiter, puis les diviser en ensembles d'entraînement, de validation et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"./../../data/05_cnn_input\"\n",
    "# data_dir = \"/tf/data/05_cnn_input\" \n",
    "\n",
    "# Dedecter si on est sous Windows ou Linux (Linux = Docker )\n",
    "if os.name == 'nt':\n",
    "    print(\"On est sous Windows.\")\n",
    "    data_dir = \"./../../data/05_cnn_input\"\n",
    "else:  # Ubuntu\n",
    "    print(\"On est sous Linux.\")\n",
    "    data_dir = \"/tf/data/05_cnn_input\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Contenu du dossier 05_cnn_input :\", os.listdir(data_dir))\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for label, category in enumerate(['balourd', 'sain']):\n",
    "    category_dir = os.path.join(data_dir, category)\n",
    "    if not os.path.exists(category_dir):\n",
    "        print(f\"Directory does not exist: {category_dir}\")\n",
    "        continue\n",
    "    print(f\"Checking directory: {category_dir}\")\n",
    "    for root, _, files in os.walk(category_dir):\n",
    "        print(f\"Found {len(files)} files in {root}\")\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "                labels.append(label)\n",
    "\n",
    "print(f\"Total directories checked: {len(['balourd', 'sain'])}\")\n",
    "print(f\"Total image paths collected: {len(image_paths)}\")\n",
    "print(\"Sample image paths:\", image_paths[:5])\n",
    "print(\"Labels distribution:\", {label: labels.count(label) for label in set(labels)})\n",
    "\n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f5ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prétraitement des images : charger les images telles quelles (sans redimensionnement ni rognage)\n",
    "def preprocess_image(image_path):\n",
    "    try:\n",
    "        img = load_img(image_path)  # Charger l'image sans redimensionnement\n",
    "        img_array = img_to_array(img)\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement de l'image {image_path} : {e}\")\n",
    "        return None\n",
    "\n",
    "# Débogage : Afficher les informations sur le jeu de données\n",
    "print(f\"Nombre total de chemins d'images trouvés : {len(image_paths)}\")\n",
    "print(\"Exemples de chemins d'images :\", image_paths[:5])\n",
    "print(\"Répartition des étiquettes :\", {label: labels.tolist().count(label) for label in set(labels)})\n",
    "\n",
    "# Appliquer le prétraitement à toutes les images\n",
    "images = np.array([img for img in (preprocess_image(path) for path in image_paths) if img is not None])\n",
    "\n",
    "# Débogage : Vérifier les images traitées\n",
    "print(f\"Nombre total d'images valides traitées : {len(images)}\")\n",
    "if len(images) > 0:\n",
    "    print(\"Dimensions de la première image :\", images[0].shape)\n",
    "\n",
    "# Diviser le jeu de données en ensembles d'entraînement, de validation et de test\n",
    "if len(images) == 0:\n",
    "    raise ValueError(\"Aucune image valide n'a été traitée. Veuillez vérifier le jeu de données.\")\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Débogage : Afficher les répartitions des ensembles de données\n",
    "print(f\"Ensemble d'entraînement : {len(X_train)} échantillons\")\n",
    "print(f\"Ensemble de validation : {len(X_val)} échantillons\")\n",
    "print(f\"Ensemble de test : {len(X_test)} échantillons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedf5f0",
   "metadata": {},
   "source": [
    "## Construction du modèle CNN\n",
    "\n",
    "Nous allons définir une architecture de réseau de neurones convolutionnel (CNN) pour traiter les images de spectrogrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "# Generate a timestamp for the filename\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Define Model Checkpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=f'best_model_{timestamp}.h5',\n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Définir le modèle CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu',input_shape=(129, 85, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # Conv2D(128, (3, 3), activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    # MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Conv2D(256, (3, 3), activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    # MaxPooling2D((2, 2)),\n",
    "\n",
    "    Dropout(0.2),\n",
    "\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    \n",
    "    # Dense(256, activation='relu'),\n",
    "    # Dropout(0.5),\n",
    "\n",
    "    # Dense(128, activation='relu'),\n",
    "    # Dropout(0.5),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Afficher le résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db346ae",
   "metadata": {},
   "source": [
    "## Entraînement du modèle et sauvegarde\n",
    "\n",
    "Nous allons compiler le modèle, l'entraîner en utilisant les ensembles d'entraînement et de validation, puis enregistrer le modèle entraîné avec une convention de nommage basée sur les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda804d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, model_checkpoint] \n",
    ")\n",
    "# Générer un nom de fichier avec un timestamp et les performances\n",
    "def generate_model_name(history, test_accuracy):\n",
    "    val_accuracy = max(history.history['val_accuracy']) * 100\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    return f\"{timestamp}_validation_res_{val_accuracy:.2f}_test_set_{test_accuracy:.2f}.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6e7b6",
   "metadata": {},
   "source": [
    "## Évaluation du modèle\n",
    "\n",
    "Nous allons évaluer le modèle entraîné sur l'ensemble de test et calculer la précision sur cet ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8cff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble de test : {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "if test_accuracy * 100 > 97:\n",
    "    # Sauvegarder le modèle avec la précision mise à jour\n",
    "    model.save(generate_model_name(history, test_accuracy * 100))\n",
    "    print(\"Modèle sauvegardé avec succès.\")\n",
    "else:\n",
    "    print(\"La précision sur l'ensemble de test est inférieure à 98%. Le modèle ne sera pas sauvegardé.\")\n",
    "\n",
    "# # Visualiser quelques prédictions\n",
    "# import matplotlib.pyplot as plt\n",
    "# predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# for i in range(16):\n",
    "#     plt.subplot(4, 4, i + 1)\n",
    "#     plt.imshow(X_test[i].astype(\"uint8\"))\n",
    "#     plt.title(f\"Label: {'balourd' if y_test[i] == 0 else 'sain'}\\nPred: {'balourd' if predictions[i] == 0 else 'sain'}\")\n",
    "#     plt.axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d48854-f592-46a5-ad91-1ca8e750bb25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
