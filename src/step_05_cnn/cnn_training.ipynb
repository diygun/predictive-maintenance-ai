{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd6ca6e",
   "metadata": {},
   "source": [
    "# Entraînement d'un CNN avec des images de spectrogrammes\n",
    "\n",
    "Ce notebook entraîne un réseau de neurones convolutionnel (CNN) en utilisant des images de spectrogrammes des vibrations du moteur. Le jeu de données est divisé en ensembles d'entraînement, de validation et de test. Le modèle entraîné est sauvegardé avec un horodatage et une convention de nommage basée sur les performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f09fe9",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques (libraries) nécessaires\n",
    "\n",
    "Nous allons importer les bibliothèques nécessaires pour le chargement des données, le prétraitement et la construction du modèle CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5061783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec5ca3",
   "metadata": {},
   "source": [
    "## Chargement et prétraitement des données\n",
    "\n",
    "Nous allons charger les images de spectrogrammes depuis le répertoire `data/05_cnn_input`, les prétraiter, puis les diviser en ensembles d'entraînement, de validation et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f21e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu du dossier 05_cnn_input : ['balourd', 'sain']\n",
      "Checking directory: ./../../data/05_cnn_input\\balourd\n",
      "Found 246 files in ./../../data/05_cnn_input\\balourd\n",
      "Checking directory: ./../../data/05_cnn_input\\sain\n",
      "Found 551 files in ./../../data/05_cnn_input\\sain\n",
      "Total directories checked: 2\n",
      "Total image paths collected: 797\n",
      "Sample image paths: ['./../../data/05_cnn_input\\\\balourd\\\\spec_rgb_0551.png', './../../data/05_cnn_input\\\\balourd\\\\spec_rgb_0552.png', './../../data/05_cnn_input\\\\balourd\\\\spec_rgb_0553.png', './../../data/05_cnn_input\\\\balourd\\\\spec_rgb_0554.png', './../../data/05_cnn_input\\\\balourd\\\\spec_rgb_0555.png']\n",
      "Labels distribution: {0: 246, 1: 551}\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./../../data/05_cnn_input\"\n",
    "\n",
    "print(\"Contenu du dossier 05_cnn_input :\", os.listdir(data_dir))\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for label, category in enumerate(['balourd', 'sain']):\n",
    "    category_dir = os.path.join(data_dir, category)\n",
    "    if not os.path.exists(category_dir):\n",
    "        print(f\"Directory does not exist: {category_dir}\")\n",
    "        continue\n",
    "    print(f\"Checking directory: {category_dir}\")\n",
    "    for root, _, files in os.walk(category_dir):\n",
    "        print(f\"Found {len(files)} files in {root}\")\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "                labels.append(label)\n",
    "\n",
    "print(f\"Total directories checked: {len(['balourd', 'sain'])}\")\n",
    "print(f\"Total image paths collected: {len(image_paths)}\")\n",
    "print(\"Sample image paths:\", image_paths[:5])\n",
    "print(\"Labels distribution:\", {label: labels.count(label) for label in set(labels)})\n",
    "\n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f5ebd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de chemins d'images trouvés : 797\n",
      "Exemples de chemins d'images : ['./../../data/05_cnn_input\\\\balourd\\\\spec_rgb_0551.png'\n",
      " './../../data/05_cnn_input\\\\balourd\\\\spec_rgb_0552.png'\n",
      " './../../data/05_cnn_input\\\\balourd\\\\spec_rgb_0553.png'\n",
      " './../../data/05_cnn_input\\\\balourd\\\\spec_rgb_0554.png'\n",
      " './../../data/05_cnn_input\\\\balourd\\\\spec_rgb_0555.png']\n",
      "Répartition des étiquettes : {np.int64(0): 246, np.int64(1): 551}\n",
      "Nombre total d'images valides traitées : 797\n",
      "Dimensions de la première image : (129, 101, 3)\n",
      "Ensemble d'entraînement : 478 échantillons\n",
      "Ensemble de validation : 159 échantillons\n",
      "Ensemble de test : 160 échantillons\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prétraitement des images : charger les images telles quelles (sans redimensionnement ni rognage)\n",
    "def preprocess_image(image_path):\n",
    "    try:\n",
    "        img = load_img(image_path)  # Charger l'image sans redimensionnement\n",
    "        img_array = img_to_array(img)\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement de l'image {image_path} : {e}\")\n",
    "        return None\n",
    "\n",
    "# Débogage : Afficher les informations sur le jeu de données\n",
    "print(f\"Nombre total de chemins d'images trouvés : {len(image_paths)}\")\n",
    "print(\"Exemples de chemins d'images :\", image_paths[:5])\n",
    "print(\"Répartition des étiquettes :\", {label: labels.tolist().count(label) for label in set(labels)})\n",
    "\n",
    "# Appliquer le prétraitement à toutes les images\n",
    "images = np.array([img for img in (preprocess_image(path) for path in image_paths) if img is not None])\n",
    "\n",
    "# Débogage : Vérifier les images traitées\n",
    "print(f\"Nombre total d'images valides traitées : {len(images)}\")\n",
    "if len(images) > 0:\n",
    "    print(\"Dimensions de la première image :\", images[0].shape)\n",
    "\n",
    "# Diviser le jeu de données en ensembles d'entraînement, de validation et de test\n",
    "if len(images) == 0:\n",
    "    raise ValueError(\"Aucune image valide n'a été traitée. Veuillez vérifier le jeu de données.\")\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Débogage : Afficher les répartitions des ensembles de données\n",
    "print(f\"Ensemble d'entraînement : {len(X_train)} échantillons\")\n",
    "print(f\"Ensemble de validation : {len(X_val)} échantillons\")\n",
    "print(f\"Ensemble de test : {len(X_test)} échantillons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedf5f0",
   "metadata": {},
   "source": [
    "## Construction du modèle CNN\n",
    "\n",
    "Nous allons définir une architecture de réseau de neurones convolutionnel (CNN) pour traiter les images de spectrogrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9e89da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17920</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,293,888</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17920\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m2,293,888\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,387,265</span> (9.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,387,265\u001b[0m (9.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,387,265</span> (9.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,387,265\u001b[0m (9.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Définir le modèle CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(129, 101, 3)),  # Updated input shape\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# model = models.Sequential([\n",
    "#     layers.InputLayer(input_shape=(img_height, img_width, 3)),\n",
    "\n",
    "#     layers.Conv2D(32, kernel_size_5_5, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(),\n",
    "\n",
    "#     layers.Conv2D(64, kernel_size_3_3, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(),\n",
    "\n",
    "#     layers.Conv2D(128, kernel_size_3_3, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(),\n",
    "\n",
    "#     layers.Conv2D(256, kernel_size_3_3, activation='relu'), # Nouveau bloc\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(),\n",
    "\n",
    "#     layers.Flatten(),\n",
    "\n",
    "#     layers.Dense(256, activation='relu'),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dropout(0.5),\n",
    "\n",
    "#     # Couche de sortie avec 2 neurones (pour chien et chat) et activation sigmoïde.\n",
    "#     layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "\n",
    "# Afficher le résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db346ae",
   "metadata": {},
   "source": [
    "## Entraînement du modèle et sauvegarde\n",
    "\n",
    "Nous allons compiler le modèle, l'entraîner en utilisant les ensembles d'entraînement et de validation, puis enregistrer le modèle entraîné avec une convention de nommage basée sur les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eda804d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5795 - loss: 24.4802 - val_accuracy: 0.4340 - val_loss: 0.7146\n",
      "Epoch 2/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6423 - loss: 0.6385 - val_accuracy: 0.7484 - val_loss: 0.4514\n",
      "Epoch 3/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8494 - loss: 0.3485 - val_accuracy: 0.9057 - val_loss: 0.2569\n",
      "Epoch 4/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8828 - loss: 0.2514 - val_accuracy: 0.9119 - val_loss: 0.2367\n",
      "Epoch 5/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9289 - loss: 0.1604 - val_accuracy: 0.9245 - val_loss: 0.1871\n",
      "Epoch 6/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9289 - loss: 0.1736 - val_accuracy: 0.9371 - val_loss: 0.1491\n",
      "Epoch 7/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9561 - loss: 0.1119 - val_accuracy: 0.9497 - val_loss: 0.1481\n",
      "Epoch 8/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9749 - loss: 0.0755 - val_accuracy: 0.9497 - val_loss: 0.1497\n",
      "Epoch 9/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9728 - loss: 0.0653 - val_accuracy: 0.9497 - val_loss: 0.1304\n",
      "Epoch 10/10\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9707 - loss: 0.0606 - val_accuracy: 0.9560 - val_loss: 0.1380\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Générer un nom de fichier avec un timestamp et les performances\n",
    "def generate_model_name(history, test_accuracy):\n",
    "    val_accuracy = max(history.history['val_accuracy']) * 100\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    return f\"{timestamp}_validation_res_{val_accuracy:.2f}_test_set_{test_accuracy:.2f}.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6e7b6",
   "metadata": {},
   "source": [
    "## Évaluation du modèle\n",
    "\n",
    "Nous allons évaluer le modèle entraîné sur l'ensemble de test et calculer la précision sur cet ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a8cff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9250 - loss: 0.2224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision sur l'ensemble de test : 92.50%\n"
     ]
    }
   ],
   "source": [
    "## Évaluation du modèle\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble de test : {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Sauvegarder le modèle avec la précision mise à jour\n",
    "model.save(generate_model_name(history, test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d48854-f592-46a5-ad91-1ca8e750bb25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
