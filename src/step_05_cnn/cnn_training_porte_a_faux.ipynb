{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd6ca6e",
   "metadata": {},
   "source": [
    "# Entraînement d'un CNN avec des images de spectrogrammes\n",
    "\n",
    "Ce notebook entraîne un réseau de neurones convolutionnel (CNN) en utilisant des images de spectrogrammes des vibrations du moteur. Le jeu de données est divisé en ensembles d'entraînement, de validation et de test. Le modèle entraîné est sauvegardé avec un horodatage et une convention de nommage basée sur les performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f09fe9",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques (libraries) nécessaires\n",
    "\n",
    "Nous allons importer les bibliothèques nécessaires pour le chargement des données, le prétraitement et la construction du modèle CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2634f2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.8.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (10.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (69.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.45.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras matplotlib numpy pandas scikit-learn pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5061783e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 11:20:34.745944: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-01 11:20:34.745989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-01 11:20:34.747136: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-01 11:20:34.753758: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec5ca3",
   "metadata": {},
   "source": [
    "## Chargement et prétraitement des données\n",
    "\n",
    "Nous allons charger les images de spectrogrammes depuis le répertoire `data/05_cnn_input`, les prétraiter, puis les diviser en ensembles d'entraînement, de validation et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f21e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On est sous Linux.\n",
      "Contenu du dossier 05_cnn_input : ['balourd', 'porteafaux', 'sain']\n",
      "Checking directory: /tf/data/05_cnn_input/porteafaux\n",
      "Found 611 files in /tf/data/05_cnn_input/porteafaux\n",
      "Checking directory: /tf/data/05_cnn_input/sain\n",
      "Found 628 files in /tf/data/05_cnn_input/sain\n",
      "Total directories checked: 2\n",
      "Total image paths collected: 1239\n",
      "Sample image paths: ['/tf/data/05_cnn_input/porteafaux/spec_rgb_1243.png', '/tf/data/05_cnn_input/porteafaux/spec_rgb_1244.png', '/tf/data/05_cnn_input/porteafaux/spec_rgb_1245.png', '/tf/data/05_cnn_input/porteafaux/spec_rgb_1246.png', '/tf/data/05_cnn_input/porteafaux/spec_rgb_1247.png']\n",
      "Labels distribution: {0: 611, 1: 628}\n"
     ]
    }
   ],
   "source": [
    "# data_dir = \"./../../data/05_cnn_input\"\n",
    "# data_dir = \"/tf/data/05_cnn_input\" \n",
    "\n",
    "# Dedecter si on est sous Windows ou Linux (Linux = Docker )\n",
    "if os.name == 'nt':\n",
    "    print(\"On est sous Windows.\")\n",
    "    data_dir = \"./../../data/05_cnn_input\"\n",
    "else:  # Ubuntu\n",
    "    print(\"On est sous Linux.\")\n",
    "    data_dir = \"/tf/data/05_cnn_input\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Contenu du dossier 05_cnn_input :\", os.listdir(data_dir))\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for label, category in enumerate(['porteafaux', 'sain']):\n",
    "    category_dir = os.path.join(data_dir, category)\n",
    "    if not os.path.exists(category_dir):\n",
    "        print(f\"Directory does not exist: {category_dir}\")\n",
    "        continue\n",
    "    print(f\"Checking directory: {category_dir}\")\n",
    "    for root, _, files in os.walk(category_dir):\n",
    "        print(f\"Found {len(files)} files in {root}\")\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "                labels.append(label)\n",
    "\n",
    "print(f\"Total directories checked: {len(['porteafaux', 'sain'])}\")\n",
    "print(f\"Total image paths collected: {len(image_paths)}\")\n",
    "print(\"Sample image paths:\", image_paths[:5])\n",
    "print(\"Labels distribution:\", {label: labels.count(label) for label in set(labels)})\n",
    "\n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f5ebd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de chemins d'images trouvés : 1239\n",
      "Exemples de chemins d'images : ['/tf/data/05_cnn_input/porteafaux/spec_rgb_1243.png'\n",
      " '/tf/data/05_cnn_input/porteafaux/spec_rgb_1244.png'\n",
      " '/tf/data/05_cnn_input/porteafaux/spec_rgb_1245.png'\n",
      " '/tf/data/05_cnn_input/porteafaux/spec_rgb_1246.png'\n",
      " '/tf/data/05_cnn_input/porteafaux/spec_rgb_1247.png']\n",
      "Répartition des étiquettes : {0: 611, 1: 628}\n",
      "Nombre total d'images valides traitées : 1239\n",
      "Dimensions de la première image : (129, 85, 3)\n",
      "Ensemble d'entraînement : 743 échantillons\n",
      "Ensemble de validation : 248 échantillons\n",
      "Ensemble de test : 248 échantillons\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prétraitement des images : charger les images telles quelles (sans redimensionnement ni rognage)\n",
    "def preprocess_image(image_path):\n",
    "    try:\n",
    "        img = load_img(image_path)  # Charger l'image sans redimensionnement\n",
    "        img_array = img_to_array(img)\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement de l'image {image_path} : {e}\")\n",
    "        return None\n",
    "\n",
    "# Débogage : Afficher les informations sur le jeu de données\n",
    "print(f\"Nombre total de chemins d'images trouvés : {len(image_paths)}\")\n",
    "print(\"Exemples de chemins d'images :\", image_paths[:5])\n",
    "print(\"Répartition des étiquettes :\", {label: labels.tolist().count(label) for label in set(labels)})\n",
    "\n",
    "# Appliquer le prétraitement à toutes les images\n",
    "images = np.array([img for img in (preprocess_image(path) for path in image_paths) if img is not None])\n",
    "\n",
    "# Débogage : Vérifier les images traitées\n",
    "print(f\"Nombre total d'images valides traitées : {len(images)}\")\n",
    "if len(images) > 0:\n",
    "    print(\"Dimensions de la première image :\", images[0].shape)\n",
    "\n",
    "# Diviser le jeu de données en ensembles d'entraînement, de validation et de test\n",
    "if len(images) == 0:\n",
    "    raise ValueError(\"Aucune image valide n'a été traitée. Veuillez vérifier le jeu de données.\")\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Débogage : Afficher les répartitions des ensembles de données\n",
    "print(f\"Ensemble d'entraînement : {len(X_train)} échantillons\")\n",
    "print(f\"Ensemble de validation : {len(X_val)} échantillons\")\n",
    "print(f\"Ensemble de test : {len(X_test)} échantillons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedf5f0",
   "metadata": {},
   "source": [
    "## Construction du modèle CNN\n",
    "\n",
    "Nous allons définir une architecture de réseau de neurones convolutionnel (CNN) pour traiter les images de spectrogrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d9e89da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 127, 83, 32)       896       \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 127, 83, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 63, 41, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 63, 41, 32)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 61, 39, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 61, 39, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 30, 19, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 30, 19, 64)        0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 30, 19, 64)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 36480)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                1167392   \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1187201 (4.53 MB)\n",
      "Trainable params: 1187009 (4.53 MB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "# Generate a timestamp for the filename\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Define Model Checkpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=f'best_model_{timestamp}.h5',\n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Définir le modèle CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu',input_shape=(129, 85, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # Conv2D(128, (3, 3), activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    # MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Conv2D(256, (3, 3), activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    # MaxPooling2D((2, 2)),\n",
    "\n",
    "    Dropout(0.2),\n",
    "\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    \n",
    "    # Dense(256, activation='relu'),\n",
    "    # Dropout(0.5),\n",
    "\n",
    "    # Dense(128, activation='relu'),\n",
    "    # Dropout(0.5),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Afficher le résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db346ae",
   "metadata": {},
   "source": [
    "## Entraînement du modèle et sauvegarde\n",
    "\n",
    "Nous allons compiler le modèle, l'entraîner en utilisant les ensembles d'entraînement et de validation, puis enregistrer le modèle entraîné avec une convention de nommage basée sur les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eda804d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 11:26:43.090154: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_3/dropout_16/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/24 [===========================>..] - ETA: 0s - loss: 1.5398 - accuracy: 0.6685\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51613, saving model to best_model_20251201_112642.h5\n",
      "24/24 [==============================] - 2s 36ms/step - loss: 1.5308 - accuracy: 0.6689 - val_loss: 1.3711 - val_accuracy: 0.5161\n",
      "Epoch 2/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.3667 - accuracy: 0.8438\n",
      "Epoch 2: val_accuracy improved from 0.51613 to 0.85484, saving model to best_model_20251201_112642.h5\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.3596 - accuracy: 0.8439 - val_loss: 0.3371 - val_accuracy: 0.8548\n",
      "Epoch 3/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.3313 - accuracy: 0.8631\n",
      "Epoch 3: val_accuracy did not improve from 0.85484\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.3271 - accuracy: 0.8668 - val_loss: 0.5297 - val_accuracy: 0.6935\n",
      "Epoch 4/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2625 - accuracy: 0.8780\n",
      "Epoch 4: val_accuracy did not improve from 0.85484\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.2664 - accuracy: 0.8802 - val_loss: 0.4208 - val_accuracy: 0.8266\n",
      "Epoch 5/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.2168 - accuracy: 0.9182\n",
      "Epoch 5: val_accuracy did not improve from 0.85484\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.2227 - accuracy: 0.9098 - val_loss: 1.5436 - val_accuracy: 0.6250\n",
      "Epoch 6/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1753 - accuracy: 0.9330\n",
      "Epoch 6: val_accuracy improved from 0.85484 to 0.90323, saving model to best_model_20251201_112642.h5\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 0.1745 - accuracy: 0.9327 - val_loss: 0.2645 - val_accuracy: 0.9032\n",
      "Epoch 7/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1459 - accuracy: 0.9479\n",
      "Epoch 7: val_accuracy did not improve from 0.90323\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.1557 - accuracy: 0.9381 - val_loss: 0.4651 - val_accuracy: 0.8024\n",
      "Epoch 8/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1540 - accuracy: 0.9420\n",
      "Epoch 8: val_accuracy did not improve from 0.90323\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.1539 - accuracy: 0.9408 - val_loss: 0.2545 - val_accuracy: 0.8911\n",
      "Epoch 9/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1462 - accuracy: 0.9494\n",
      "Epoch 9: val_accuracy did not improve from 0.90323\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.1465 - accuracy: 0.9462 - val_loss: 1.7014 - val_accuracy: 0.5323\n",
      "Epoch 10/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1641 - accuracy: 0.9286\n",
      "Epoch 10: val_accuracy did not improve from 0.90323\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.1615 - accuracy: 0.9287 - val_loss: 0.5406 - val_accuracy: 0.8468\n",
      "Epoch 11/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1270 - accuracy: 0.9583\n",
      "Epoch 11: val_accuracy did not improve from 0.90323\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.1237 - accuracy: 0.9596 - val_loss: 0.2496 - val_accuracy: 0.8992\n",
      "Epoch 12/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1500 - accuracy: 0.9598\n",
      "Epoch 12: val_accuracy did not improve from 0.90323\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.1504 - accuracy: 0.9556 - val_loss: 0.4451 - val_accuracy: 0.8387\n",
      "Epoch 13/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1205 - accuracy: 0.9509\n",
      "Epoch 13: val_accuracy did not improve from 0.90323\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.1232 - accuracy: 0.9475 - val_loss: 0.8336 - val_accuracy: 0.7379\n",
      "Epoch 14/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1122 - accuracy: 0.9554\n",
      "Epoch 14: val_accuracy did not improve from 0.90323\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.1098 - accuracy: 0.9596 - val_loss: 0.8098 - val_accuracy: 0.7863\n",
      "Epoch 15/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.1092 - accuracy: 0.9613\n",
      "Epoch 15: val_accuracy did not improve from 0.90323\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.1064 - accuracy: 0.9623 - val_loss: 1.3648 - val_accuracy: 0.7339\n",
      "Epoch 16/100\n",
      "21/24 [=========================>....] - ETA: 0s - loss: 0.0997 - accuracy: 0.9628Restoring model weights from the end of the best epoch: 11.\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.90323\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 0.0968 - accuracy: 0.9650 - val_loss: 1.8434 - val_accuracy: 0.6653\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, model_checkpoint] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6e7b6",
   "metadata": {},
   "source": [
    "## Évaluation du modèle\n",
    "\n",
    "Nous allons évaluer le modèle entraîné sur l'ensemble de test et calculer la précision sur cet ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a8cff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2271 - accuracy: 0.9194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision sur l'ensemble de test : 91.94%\n",
      "Modèle sauvegardé avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Générer un nom de fichier avec un timestamp et les performances\n",
    "def generate_model_name(history, test_accuracy):\n",
    "    val_accuracy = max(history.history['val_accuracy']) * 100\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    return f\"{timestamp}_validation_res_{val_accuracy:.2f}_test_set_{test_accuracy:.2f}_porte_a_faux.h5\"\n",
    "\n",
    "## Évaluation du modèle sur l'ensemble de test\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Précision sur l'ensemble de test : {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "if test_accuracy * 100 > 88:\n",
    "    # Sauvegarder le modèle avec la précision mise à jour\n",
    "    model.save(generate_model_name(history, test_accuracy * 100))\n",
    "    print(\"Modèle sauvegardé avec succès.\")\n",
    "else:\n",
    "    print(\"La précision sur l'ensemble de test est inférieure à 88%. Le modèle ne sera pas sauvegardé.\")\n",
    "\n",
    "# # Visualiser quelques prédictions\n",
    "# import matplotlib.pyplot as plt\n",
    "# predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# for i in range(16):\n",
    "#     plt.subplot(4, 4, i + 1)\n",
    "#     plt.imshow(X_test[i].astype(\"uint8\"))\n",
    "#     plt.title(f\"Label: {'porteafaux' if y_test[i] == 0 else 'sain'}\\nPred: {'porteafaux' if predictions[i] == 0 else 'sain'}\")\n",
    "#     plt.axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d48854-f592-46a5-ad91-1ca8e750bb25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
